{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2724f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.signal import find_peaks\n",
    "import librosa\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85cca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_TIME = 30e-3\n",
    "FRAME_SHIFT_TIME = 10e-3\n",
    "THRESHOLD_VOWEL_SILENCE_BY_ENERGY = 8.5e-3\n",
    "FFT_POINTS = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1c9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(signal, fs):\n",
    "\tsignal_sample = len(signal)\n",
    "\tframe_sample = int(FRAME_TIME * fs)\n",
    "\tframe_shift_sample = int(FRAME_SHIFT_TIME * fs)\n",
    "\tleft, right = 0, frame_sample\n",
    "\tframes = []\n",
    "\twhile right < signal_sample:\n",
    "\t\tframes.append(signal[left:right])\n",
    "\t\tleft += frame_shift_sample\n",
    "\t\tright += frame_shift_sample\n",
    "\treturn np.array(frames)\n",
    "\n",
    "def energy(x):\n",
    "\treturn np.sum(x * x)\n",
    "\n",
    "def get_frame_vowel(signal, fs):\n",
    "\tframes = get_frames(signal, fs)\n",
    "\tmax_energy = 0\n",
    "\tfor frame in frames:\n",
    "\t\tmax_energy = max(max_energy, energy(frame))\n",
    "\tframe_vowel = []\n",
    "\tfor frame in frames:\n",
    "\t\tif energy(frame) >= max_energy * THRESHOLD_VOWEL_SILENCE_BY_ENERGY:\n",
    "\t\t\tframe_vowel.append(frame)\n",
    "\tn = len(frame_vowel)\n",
    "\treturn frame_vowel[n // 3 : n // 3 * 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8dcac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[73.33333333333333,\n",
       "  80.0,\n",
       "  76.19047619047619,\n",
       "  73.33333333333333,\n",
       "  70.47619047619048,\n",
       "  66.66666666666666],\n",
       " [73.33333333333333,\n",
       "  80.0,\n",
       "  79.04761904761905,\n",
       "  70.47619047619048,\n",
       "  74.28571428571429,\n",
       "  80.95238095238095],\n",
       " [73.33333333333333,\n",
       "  80.0,\n",
       "  76.19047619047619,\n",
       "  70.47619047619048,\n",
       "  77.14285714285715,\n",
       "  71.42857142857143],\n",
       " [73.33333333333333,\n",
       "  80.0,\n",
       "  78.0952380952381,\n",
       "  76.19047619047619,\n",
       "  73.33333333333333,\n",
       "  75.23809523809524],\n",
       " [73.33333333333333,\n",
       "  80.0,\n",
       "  77.14285714285715,\n",
       "  73.33333333333333,\n",
       "  67.61904761904762,\n",
       "  76.19047619047619]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_fft = []\n",
    "for t in range(5):\n",
    "    rate = []\n",
    "    for N_CLUSTERS in range(1, 7):\n",
    "        vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "        training_folder = './NguyenAmHuanLuyen-16k' \n",
    "        training_folders = []\n",
    "        for folder in os.listdir(training_folder):\n",
    "            training_folders.append(folder)\n",
    "\n",
    "        vowels_feature = {}\n",
    "\n",
    "        for vowel in vowels:\n",
    "            features = []\n",
    "\n",
    "            for folder in training_folders:\n",
    "                signal, fs = sf.read(training_folder + '/' + folder + '/' + vowel + '.wav')\n",
    "                signal = signal / np.max(signal)\n",
    "                frames = get_frame_vowel(signal, fs)\n",
    "                ffts = []\n",
    "                for frame in frames:\n",
    "                    frame = frame * np.hamming(len(frame))\n",
    "                    vfft = np.log(np.abs(fft(frame, FFT_POINTS)))[:FFT_POINTS // 2]\n",
    "                    ffts.append(vfft)\n",
    "\n",
    "                feature = np.mean(ffts, axis=0) \n",
    "                features.append(feature)\n",
    "\n",
    "            kmeans = KMeans(n_clusters=N_CLUSTERS).fit(features)\n",
    "            clusters = kmeans.cluster_centers_\n",
    "            vowels_feature[vowel] = clusters\n",
    "\n",
    "\n",
    "        # TEST\n",
    "        vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "        testing_folder = './NguyenAmKiemThu-16k' \n",
    "        testing_folders = []\n",
    "        for folder in os.listdir(testing_folder):\n",
    "            testing_folders.append(folder)\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        ok = 0\n",
    "\n",
    "\n",
    "        for vowel in vowels:\n",
    "            features = []\n",
    "\n",
    "            for folder in testing_folders:\n",
    "                signal, fs = sf.read(testing_folder + '/' + folder + '/' + vowel + '.wav')\n",
    "                signal = signal / np.max(signal)\n",
    "                frames = get_frame_vowel(signal, fs)\n",
    "                ffts = []\n",
    "                for frame in frames:\n",
    "                    frame = frame * np.hamming(len(frame))\n",
    "                    vfft = np.log(np.abs(fft(frame, FFT_POINTS)))[:FFT_POINTS // 2]\n",
    "                    ffts.append(vfft)\n",
    "\n",
    "                feature = np.mean(ffts, axis=0) \n",
    "                y_true.append(vowel)\n",
    "\n",
    "                predict_vowel = '#'\n",
    "                min_dist = 1e20\n",
    "                for v in vowels:\n",
    "                    for i in vowels_feature[v]:\n",
    "                        dist = np.linalg.norm(feature - i)\n",
    "                        if dist < min_dist:\n",
    "                            min_dist = dist\n",
    "                            predict_vowel = v\n",
    "\n",
    "                y_pred.append(predict_vowel)\n",
    "\n",
    "                if vowel == predict_vowel:\n",
    "                    ok += 1\n",
    "\n",
    "        rate.append(ok / len(y_pred) * 100)\n",
    "    rate_fft.append(rate)\n",
    "rate_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2efd088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73.33333333, 80.        , 77.33333333, 72.76190476, 72.57142857,\n",
       "       74.0952381 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rate_fft, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
